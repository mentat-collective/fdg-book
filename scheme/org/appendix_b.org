#+title: Appendix B: Our Notation
#+STARTUP: noindent


#+begin_quote
An adequate notation should be understood by at
least two people, one of whom may be the author.

Abdus Salam (1950).
#+end_quote


We adopt a /functional mathematical notation/ that is close to that used by
Spivak in his /Calculus on Manifolds/ [17]. The use of functional notation
avoids many of the ambiguities of traditional mathematical notation that can
impede clear reasoning. Functional notation carefully distinguishes the function
from the value of the function when applied to particular arguments. In
functional notation mathematical expressions are unambiguous and self-contained.

We adopt a /generic arithmetic/ in which the basic arithmetic operations, such as
addition and multiplication, are extended to a wide variety of mathematical
types. Thus, for example, the addition operator $+$ can be applied to numbers,
tuples of numbers, matrices, functions, etc. Generic arithmetic formalizes the
common informal practice used to manipulate mathematical objects.

We often want to manipulate aggregate quantities, such as the collection of all
of the rectangular coordinates of a collection of particles, without explicitly
manipulating the component parts. Tensor arithmetic provides a traditional way
of manipulating aggregate objects: Indices label the parts; conventions, such as
the summation convention, are introduced to manipulate the indices. We introduce
a /tuple arithmetic/ as an alternative way of manipulating aggregate quantities
that usually lets us avoid labeling the parts with indices. Tuple arithmetic is
inspired by tensor arithmetic but it is more general: not all of the components
of a tuple need to be of the same size or type.

The mathematical notation is in one-to-one correspondence with expressions of
the computer language /Scheme/ [10]. Scheme is based on the $\lambda$-calculus
[5] and directly supports the manipulation of functions. We augment Scheme with
symbolic, numerical, and generic features to support our applications. For a
simple introduction to Scheme, see Appendix A. The correspondence between the
mathematical notation and Scheme requires that mathematical expressions be
unambiguous and self-contained. Scheme provides immediate feedback in
verification of mathematical deductions and facilitates the exploration of the
behavior of systems.

** Functions

   The expression $f(x)$ denotes the value of the function $f$ at the given
   argument $x$; when we wish to denote the function we write just $f$.
   Functions may take several arguments. For example, we may have the function
   that gives the Euclidean distance between two points in the plane given by
   their rectangular coordinates:

\begin{equation}
d(x_1, y_1, x_2, y_2) = \sqrt{(x_2 - x_1)^2 + (y_2 - y_1)^2 }.
\end{equation}

   In Scheme we can write this as:

   #+begin_src scheme
(define (d x1 y1 x2 y2)
  (sqrt (+ (square (- x2 x1)) (square (- y2 y1)))))
   #+end_src

   Functions may be composed if the range of one overlaps the domain of the
   other. The composition of functions is constructed by passing the output of
   one to the input of the other. We write the composition of two functions
   using the $\circ$ operator:

\begin{equation}
(f \circ g) : x \mapsto (f \circ g)(x) = f(g(x)).
\end{equation}

   A procedure =h= that computes the cube of the sine of its argument may be
   defined by composing the procedures =cube= and =sin=:

   #+begin_src scheme :results wrap :exports both :cache yes
(define h (compose cube sin))

(h 2)
;; .7518269446689928
   #+end_src

   Which is the same as

   #+begin_src scheme :results wrap :exports both :cache yes
(cube (sin 2))
;; .7518269446689928
   #+end_src

   Arithmetic is extended to the manipulation of functions: the usual
   mathematical operations may be applied to functions. Examples are addition
   and multiplication; we may add or multiply two functions if they take the
   same kinds of arguments and if their values can be added or multiplied:

\begin{equation}
\begin{aligned}
(f + g)(x) &= f(x) + g(x), \\
(fg)(x) &= f(x)g(x).
\end{aligned}
\end{equation}

   A procedure =g= that multiplies the cube of its argument by the sine of its
   argument is

   #+begin_src scheme :results wrap :exports both :cache yes
(define g (* cube sin))

(g 2)
;; 7.274379414605454
   #+end_src

   #+begin_src scheme :results wrap :exports both :cache yes
(* (cube 2) (sin 2))
;; 7.274379414605454
   #+end_src

** Symbolic Values

   As in usual mathematical notation, arithmetic is extended to allow the use of
   symbols that represent unknown or incompletely specified mathematical
   objects. These symbols are manipulated as if they had values of a known type.
   By default, a Scheme symbol is assumed to represent a real number. So the
   expression ='a= is a literal Scheme symbol that represents an unspecified real
   number:

   #+begin_src scheme :results wrap :exports both :cache yes
((compose cube sin) 'a)
;; (expt (sin a) 3)
   #+end_src

   The default printer simplifies the expression,[fn:1] and displays it in a
   readable form. We can use the simplifier to verify a trigonometric identity:

   #+begin_src scheme :results wrap :exports both :cache yes
((- (+ (square sin) (square cos)) 1) 'a)
;; 0
   #+end_src

   Just as it is useful to be able to manipulate symbolic numbers, it is useful
   to be able to manipulate symbolic functions. The procedure =literal-function=
   makes a procedure that acts as a function having no properties other than its
   name. By default, a literal function is defined to take one real argument and
   produce one real value. For example, we may want to work with a function $f :
   \mathbf{R} \to \mathbf{R}$:

   #+begin_src scheme :results wrap :exports both :cache yes
((literal-function 'f) 'x)
;; (f x)
   #+end_src

   #+begin_src scheme :results wrap :exports both :cache yes
((compose (literal-function 'f) (literal-function 'g)) 'x)
;; (f (g x))
   #+end_src

   We can also make literal functions of multiple, possibly structured arguments
   that return structured values. For example, to denote a literal function
   named =g= that takes two real arguments and returns a real value ($g :
   \mathbf{R} \times \mathbf{R} \to \mathbf{R}$) we may write:

   #+begin_src scheme :results wrap :exports both :cache yes
(define g (literal-function 'g (-> (X Real Real) Real)))

(g 'x 'y)
;; (g x y)
   #+end_src

   We may use such a literal function anywhere that an explicit function of the
   same type may be used.

   There is a whole language for describing the type of a literal function in
   terms of the number of arguments, the types of the arguments, and the types
   of the values. Here we describe a function that maps pairs of real numbers to
   real numbers with the expression =(-> (X Real Real) Real)=. Later we will
   introduce structured arguments and values and show extensions of literal
   functions to handle these.

** Tuples

   There are two kinds of tuples: /up/ tuples and /down/ tuples. We write tuples
   as ordered lists of their components; a tuple is delimited by parentheses if
   it is an up tuple and by square brackets if it is a down tuple. For example,
   the up tuple $v$ of velocity components $v^0$, $v^1$, and $v^2$ is

\begin{equation}
v = (v^0, v^1, v^2).
\end{equation}

   The down tuple $p$ of momentum components $p_0$, $p_1$, and $p_2$ is

\begin{equation}
p = [p_0, p_1, p_2].
\end{equation}

   A component of an up tuple is usually identified by a superscript. A
   component of a down tuple is usually identified by a subscript. We use
   zero-based indexing when referring to tuple elements. This notation follows
   the usual convention in tensor arithmetic.

   We make tuples with the constructors =up= and =down=:


   #+begin_src scheme :results wrap :exports both :cache yes
(define v (up 'v^0 'v^1 'v^2))
v
;; (up vˆ0 vˆ1 vˆ2)
   #+end_src

   #+begin_src scheme :results wrap :exports both :cache yes
(define p (down 'p_0 'p_1 'p_2))
p
;; (down p_0 p_1 p_2)

   #+end_src

   Note that =v^0= and =p_2= are just symbols. The caret and underline
   characters are symbol constituents, so there is no meaning other than
   mnemonic to the structure of these symbols. However, our software can also
   display expressions using $\TeX$, and then these decorations turn into
   superscripts and subscripts.

   Tuple arithmetic is different from the usual tensor arithmetic in that the
   components of a tuple may also be tuples and different components need not
   have the same structure. For example, a tuple structure $s$ of phase-space
   states is

\begin{equation}
s = \left(t, \left(x, y\right), \left[p_x, p_y \right] \right).
\end{equation}

   It is an up tuple of the time, the coordinates, and the momenta. The time $t$
   has no substructure. The coordinates are an up tuple of the coordinate
   components $x$ and $y$. The momentum is a down tuple of the momentum
   components $p_x$ and $p_y$. In Scheme this is written:

   #+begin_src scheme
(define s (up 't (up 'x 'y) (down 'p_x 'p_y)))
   #+end_src

   In order to reference components of tuple structures there are selector
   functions, for example:

\begin{equation}
\begin{aligned}
I(s) &= s \\
I_0(s) &= y \\
I_1(s) &= (x,y) \\
I_2(s) &= [p_x, p_y] \\
I_{1,0}(s) &= x \\
&\ldots \\
I_{2,1}(s) &= p_y.
\end{aligned}
\end{equation}

   The sequence of integer subscripts on the selector describes the access chain
   to the desired component.

   The procedure =component= is the general selector procedure that implements
   the selector function $I_z$:

   #+begin_src scheme :results wrap :exports both :cache yes
((component 0 1) (up (up 'a 'b) (up 'c 'd)))
;; b
   #+end_src

   To access a component of a tuple we may also use the selector procedure
   =ref=, which takes a tuple and an index and returns the indicated element of
   the tuple:

   #+begin_src scheme :results wrap :exports both :cache yes
(ref (up 'a 'b 'c) 1)
;; b
   #+end_src

   We use zero-based indexing everywhere. The procedure =ref= can be used to
   access any substructure of a tree of tuples:

   #+begin_src scheme :results wrap :exports both :cache yes
(ref (up (up 'a 'b) (up 'c 'd)) 0 1)
;; b
   #+end_src

   Two up tuples of the same length may be added or subtracted, elementwise, to
   produce an up tuple, if the components are compatible for addition.
   Similarly, two down tuples of the same length may be added or subtracted,
   elementwise, to produce a down tuple, if the components are compatible for
   addition.

   Any tuple may be multiplied by a number by multiplying each component by the
   number. Numbers may, of course, be multiplied. Tuples that are compatible for
   addition form a vector space.

   For convenience we define the square of a tuple to be the sum of the squares
   of the components of the tuple. Tuples can be multiplied, as described below,
   but the square of a tuple is not the product of the tuple with itself.

   The meaning of multiplication of tuples depends on the structure of the
   tuples. Two tuples are compatible for contraction if they are of opposite
   types, they are of the same length, and corresponding elements have the
   following property: either they are both tuples and are compatible for
   contraction, or at least one is not a tuple. If two tuples are compatible for
   contraction then generic multiplication is interpreted as contraction: the
   result is the sum of the products of corresponding components of the tuples.
   For example, $p$ and $v$ introduced in equations (B.4) and (B.5) above are
   compatible for contraction; the product is

\begin{equation}
pv = p_0 v^0 + p_1 v^1 + p_2 v^2.
\end{equation}

   So the product of tuples that are compatible for contraction is an inner
   product. Using the tuples =p= and =v= defined above gives us

   #+begin_src scheme :results wrap :exports both :cache yes
(* p v)
;; (+ (* p 0 vˆ0) (* p 1 vˆ1) (* p 2 vˆ2))
   #+end_src

   Contraction of tuples is commutative: $pv = vp$. Caution: Multiplication of
   tuples that are compatible for contraction is, in general, not associative.
   For example, let $u = (5, 2)$, $v = (11, 13)$, and $g = \left[\left[3,
   5\right] , \left[7, 9\right]\right]$. Then $u(gv) = 964$, but $(ug)v = 878$.
   The expression $ugv$ is ambiguous. An expression that has this ambiguity does
   not occur in this book.

   The rule for multiplying two structures that are not compatible for
   contraction is simple. If $A$ and $B$ are not compatible for contraction, the
   product $AB$ is a tuple of type $B$ whose components are the products of $A$
   and the components of $B$. The same rule is applied recursively in
   multiplying the components. So if $B = (B^0, B^1, B^2)$, the product of $A$
   and $B$ is

\begin{equation}
AB = (AB^0, AB^1, AB^2).
\end{equation}

   If $A$ and $C$ are not compatible for contraction and $C = [C_0, C_1, C_2]$,
   the product is

\begin{equation}
AB = [AC_0, AC_1, AC_2].
\end{equation}

   Tuple structures can be made to represent linear transformations. For
   example, the rotation commonly represented by the matrix

\begin{equation}
\left[\begin{array}{cc}
\cos \theta & -\sin \theta \\
\sin \theta & \cos \theta
\end{array}\right]
\end{equation}

   can be represented as a tuple structure:[fn:2]

\begin{equation}
\left[\left(\begin{array}{c}
\cos \theta \\
\sin \theta
\end{array}\right)\left(\begin{array}{c}
-\sin \theta \\
\cos \theta
\end{array}\right)\right].
\end{equation}

   Such a tuple is compatible for contraction with an up tuple that represents a
   vector. So, for example:

\begin{equation}
\left[\left(\begin{array}{c}
\cos \theta \\
\sin \theta
\end{array}\right) \left(\begin{array}{c}
-\sin \theta \\
\cos \theta
\end{array}\right)\right] \left(\begin{array}{c}
x \\
y
\end{array}\right) =
\left(\begin{array}{c}
x \cos \theta - y \sin \theta \\
x \sin \theta + y \cos \theta
\end{array}\right).
\end{equation}

   The product of two tuples that represent linear transformations -- which are
   not compatible for contraction -- represents the composition of the linear
   transformations. For example, the product of the tuples representing two
   rotations is

\begin{equation}
\begin{gathered}
{\left[\left(\begin{array}{c}
\cos \theta \\
\sin \theta
\end{array}\right)\left(\begin{array}{c}
-\sin \theta \\
\cos \theta
\end{array}\right)\right]\left[\left(\begin{array}{c}
\cos \varphi \\
\sin \varphi
\end{array}\right)\left(\begin{array}{c}
-\sin \varphi \\
\cos \varphi
\end{array}\right)\right]} \\
=\left[\left(\begin{array}{c}
\cos (\theta+\varphi) \\
\sin (\theta+\varphi)
\end{array}\right)\left(\begin{array}{c}
-\sin (\theta+\varphi) \\
\cos (\theta+\varphi)
\end{array}\right)\right].
\end{gathered}
\end{equation}

   Multiplication of tuples that represent linear transformations is associative
   but generally not commutative, just as the composition of the transformations
   is associative but not generally commutative.

** Derivatives

   The derivative of a function $f$ is a function, denoted by $Df$. Our
   notational convention is that $D$ is a high-precedence operator. Thus $D$
   operates on the adjacent function before any other application occurs:
   $Df(x)$ is the same as $(Df)(x)$. Higher-order derivatives are described by
   exponentiating the derivative operator. Thus the $n$th derivative of a function
   $f$ is notated as $D^n f$.

   The Scheme procedure for producing the derivative of a function is named =D=.
   The derivative of the =sin= procedure is a procedure that computes =cos=:

   #+begin_src scheme :results wrap :exports both :cache yes
(define derivative-of-sine (D sin))

(derivative-of-sine 'x)
;; (cos x)
   #+end_src

   The derivative of a function $f$ is the function $Df$ whose value for a
   particular argument is something that can be multiplied by an increment
   $\Delta x$ in the argument to get a linear approximation to the increment in
   the value of $f$:

\begin{equation}
f(x + \Delta x) \approx f(x) + Df(x)\Delta x.
\end{equation}

   For example, let $f$ be the function that cubes its argument ($f(x) = x^3$);
   then $Df$ is the function that yields three times the square of its argument
   ($Df(y) = 3y^2$). So $f(5) = 125$ and $Df(5) = 75$. The value of $f$ with
   argument $x + \Delta x$ is

\begin{equation}
f(x + \Delta x) = (x + \Delta{x})^3 = x^3 + 3x^2 \Delta{x} + 3x\Delta{x}^2 + \Delta{x}^3
\end{equation}

   and

\begin{equation}
Df(x)\Delta{x} = 3x^2 \Delta{x}.
\end{equation}

   So $Df(x)$ multiplied by $\Delta x$ gives us the term in $f(x + \Delta x)$
   that is linear in $\Delta x$, providing a good approximation to $f(x + \Delta
   x) − f(x)$ when $\Delta x$ is small.

   Derivatives of compositions obey the chain rule:

\begin{equation}
D(f \circ g) = \left( (Df) \circ g\right) \cdot Dg.
\end{equation}

   So at $x$,

\begin{equation}
(D(f \circ g))(x) = Df(g(x)) \cdot Dg(x).
\end{equation}

   =D= is an example of an operator. An operator is like a function except that
   multiplication of operators is interpreted as composition, whereas
   multiplication of functions is multiplication of the values (see equation
   B.3). If $D$ were an ordinary function, then the rule for multiplication
   would imply that $D^2 f$ would just be the product of $Df$ with itself, which
   is not what is intended. A product of a number and an operator scales the
   operator. So, for example

   #+begin_src scheme :results wrap :exports both :cache yes
(((* 5 D) cos) 'x)
;; (* -5 (sin x))
   #+end_src

   Arithmetic is extended to allow manipulation of operators. A typical operator
   is $(D + I)(D − I) = D^2 − I$, where $I$ is the identity operator, subtracts
   a function from its second derivative. Such an operator can be constructed
   and used in Scheme as follows:

   #+begin_src scheme :results wrap :exports both :cache yes
(((* (+ D I) (- D I)) (literal-function 'f)) 'x)
;; (+ (((expt D 2) f) x) (* -1 (f x)))
   #+end_src

** Derivatives of Functions of Multiple Arguments

   The derivative generalizes to functions that take multiple arguments. The
   derivative of a real-valued function of multiple arguments is an object whose
   contraction with the tuple of increments in the arguments gives a linear
   approximation to the increment in the function's value.

   A function of multiple arguments can be thought of as a function of an up
   tuple of those arguments. Thus an incremental argument tuple is an up tuple
   of components, one for each argument position. The derivative of such a
   function is a down tuple of the partial derivatives of the function with
   respect to each argument position

   Suppose we have a real-valued function $g$ of two real-valued arguments, and
   we want to approximate the increment in the value of $g$ from its value at
   $x, y$. If the arguments are incremented by the tuple $(\Delta x, \Delta y)$
   we compute:

\begin{equation}
\begin{aligned}
Dg(x,y) \cdot (\Delta x, \Delta y) &= \left[ \partial_0 g(x,y) + \partial_1 g(x,y) \right] \cdot (\Delta x, \Delta y) \\
&= \partial_0 g(x,y)\Delta x + \partial_1 g(x,y)\Delta y.
\end{aligned}
\end{equation}

   Using the two-argument literal function =g= defined on page 198, we have:

#+begin_src scheme :results wrap :exports both :cache yes
((D g) 'x 'y)
;; (down (((partial 0) g) x y) (((partial 1) g) x y))
#+end_src

   In general, partial derivatives are just the components of the derivative of
   a function that takes multiple arguments (or structured arguments or both;
   see below). So a partial derivative of a function is a composition of a
   component selector and the derivative of that function.[fn:3] Indeed:

\begin{equation}
\partial_0 g = I_0 \circ Dg,
\end{equation}

\begin{equation}
\partial_1 g = I_1 \circ Dg.
\end{equation}

   Concretely, if

\begin{equation}
g(x, y) = x^3 y^5
\end{equation}

   then

\begin{equation}
Dg(x, y) = [3x^2y^5, 5x^3y^4]
\end{equation}

   and the first-order approximation of the increment for changing the arguments
   by $\Delta x$ and $\Delta y$ is

\begin{equation}
\begin{aligned}
g(x + \Delta x, y + \Delta y) - g(x,y) &\approx [3x^2y^5, 5x^3y^4] \cdot (\Delta x, \Delta y) \\
&= 3x^2y^5\Delta x + 5x^3y^4\Delta y.
\end{aligned}
\end{equation}

   Partial derivatives of compositions also obey a chain rule:

\begin{equation}
\partial_i(f \circ g) = ((Df) \circ g) \cdot \partial_i g.
\end{equation}

   So if $x$ is a tuple of arguments, then

\begin{equation}
(\partial_i(f \circ g))(x) = Df(g(x)) \cdot \partial_i g(x).
\end{equation}

   Mathematical notation usually does not distinguish functions of multiple
   arguments and functions of the tuple of arguments. Let $h((x, y)) = g(x, y)$.
   The function $h$, which takes a tuple of arguments $x$ and $y$, is not
   distinguished from the function $g$ that takes arguments $x$ and $y$. We use
   both ways of defining functions of multiple arguments. The derivatives of
   both kinds of functions are compatible for contraction with a tuple of
   increments to the arguments. Scheme comes in handy here:

#+begin_src scheme
(define (h s)
  (g (ref s 0) (ref s 1)))
#+end_src

#+begin_src scheme :results wrap :exports both :cache yes
(h (up 'x 'y))
;; (g x y)
#+end_src

#+begin_src scheme :results wrap :exports both :cache yes
((D g) 'x 'y)
;; (down (((partial 0) g) x y) (((partial 1) g) x y))
#+end_src

#+begin_src scheme :results wrap :exports both :cache yes
((D h) (up 'x 'y))
(down (((partial 0) g) x y) (((partial 1) g) x y))
#+end_src

   A phase-space state function is a function of time, coordinates, and momenta.
   Let $H$ be such a function. The value of $H$ is $H\left(t,(x, y), [p_x,
   p_y]\right)$ for time $t$, coordinates $(x, y)$, and momenta $[p_x, p_y]$.
   Let $s$ be the phase-space state tuple as in (B.6):

\begin{equation}
s = \left(t, (x, y), [p_x, p_y] \right).
\end{equation}

   The value of $H$ for argument tuple $s$ is $H(s)$. We use both ways of
   writing the value of $H$.

   We often show a function of multiple arguments that include tuples by
   indicating the boundaries of the argument tuples with semicolons and
   separating their components with commas. If $H$ is a function of phase-space
   states with arguments $t$, $(x, y)$, and $[p_x, p_y]$, we may write $H(t; x,
   y; p_x, p_y)$. This notation loses the up/down distinction, but our
   semicolon-and-comma notation is convenient and reasonably unambiguous.

   The derivative of $H$ is a function that produces an object that can be
   contracted with an increment in the argument structure to produce an
   increment in the function's value. The derivative is a down tuple of three
   partial derivatives. The first partial derivative is the partial derivative
   with respect to the numerical argument. The second partial derivative is a
   down tuple of partial derivatives with respect to each component of the
   up-tuple argument. The third partial derivative is an up tuple of partial
   derivatives with respect to each component of the down-tuple argument:

\begin{equation}
\begin{aligned}
DH(s) &= \left[\partial_0 H(s), \partial_1 H(s), \partial_2 H(s) \right] \\
&= \left[\partial_0 H(s), \left[ \partial_{1,0} H(s), \partial_{1,1} H(s) \right], \
\left[ \partial_{2,0} H(s), \partial_{2,1} H(s) \right] \right],
\end{aligned}
\end{equation}

   where $\partial_{1,0}$ indicates the partial derivative with respect to the
   first component (index 0) of the second argument (index 1) of the function,
   and so on. Indeed, $\partial_z F = I_z \circ DF$ for any function $F$ and
   access chain $z$. So, if we let $\Delta s$ be an incremental phase-space
   state tuple,

\begin{equation}
\Delta s = \left(\Delta t, (\Delta x, \Delta y), [\Delta p_x, \Delta p_y] \right)
\end{equation}

   then

\begin{equation}
\begin{aligned}
DH(s)\Delta s = &\partial_0 H(s)\Delta t \\
&+ \partial_{1,0} H(s)\Delta x + \partial_{1,1} H(s)\Delta y \\
&+ \partial_{2,0} H(s)\Delta p_x + \partial_{2,1} H(s)\Delta p_y.
\end{aligned}
\end{equation}

   Caution: Partial derivative operators with respect to different structured
   arguments generally do not commute.

   In Scheme we must make explicit choices. We usually assume that phase-space
   state functions are functions of the tuple. For example,

#+begin_src scheme
(define H
  (literal-function
   'H
   (-> (UP Real (UP Real Real) (DOWN Real Real)) Real)))
#+end_src

#+begin_src scheme :results wrap :exports both :cache yes
(H s)
;; (H (up t (up x y) (down p x p y)))
#+end_src

#+begin_src scheme :results wrap :exports both :cache yes
((D H) s)
;; (down
;;  (((partial 0) H) (up t (up_x y) (down p_x p_y)))
;;  (down (((partial 1 0) H) (up t (up_x y) (down p_x p_y)))
;;        (((partial 1 1) H) (up t (up_x y) (down p_x p_y))))
;;  (up (((partial 2 0) H) (up t (up_x y) (down p_x p_y)))
;;      (((partial 2 1) H) (up t (up_x y) (down p_x p_y)))))
#+end_src

** Structured Results

   Some functions produce structured outputs. A function whose output is a tuple
   is equivalent to a tuple of component functions each of which produces one
   component of the output tuple.

   For example, a function that takes one numerical argument and produces a
   structure of outputs may be used to describe a curve through space. The
   following function describes a helical path around the $\hat{z}$-axis in
   3-dimensional space:

\begin{equation}
h(t) = (\cos t, \sin t, t) = (\cos, \sin, I)(t).
\end{equation}

   The derivative is just the up tuple of the derivatives of each component of
   the function:

\begin{equation}
Dh(t) = (-\sin t, \cos t, 1).
\end{equation}

   In Scheme we can write

   #+begin_src scheme
(define (helix t)
  (up (cos t) (sin t) t))
   #+end_src

   or just

   #+begin_src scheme
(define helix (up cos sin identity))
   #+end_src

   Its derivative is just the up tuple of the derivatives of each component of
   the function:

   #+begin_src scheme :results wrap :exports both :cache yes
((D helix) 't)
(up (* -1 (sin t)) (cos t) 1)
   #+end_src

   In general, a function that produces structured outputs is just treated as a
   structure of functions, one for each of the components. The derivative of a
   function of structured inputs that produces structured outputs is an object
   that when contracted with an incremental input structure produces a linear
   approximation to the incremental output. Thus, if we define function $g$ by

\begin{equation}
g(x, y) = \left((x+y)^2, (y-x)^3, e^{x+y} \right),
\end{equation}

   then the derivative of $g$ is

\begin{equation}
D g(x, y)=\left[\left(\begin{array}{c}
2(x+y) \\
-3(y-x)^{2} \\
e^{x+y}
\end{array}\right),\left(\begin{array}{c}
2(x+y) \\
3(y-x)^{2} \\
e^{x+y}
\end{array}\right)\right]
\end{equation}

   In Scheme:

   #+begin_src scheme
(define (g x y)
  (up (square (+ x y)) (cube (- y x)) (exp (+ x y))))
   #+end_src

   #+begin_src scheme :results wrap :exports both :cache yes
((D g) 'x 'y)
;; (down (up (+ (* 2 x) (* 2 y))
;;           (+ (* -3 (expt x 2)) (* 6 x y) (* -3 (expt y 2)))
;;           (* (exp y) (exp x)))
;;       (up (+ (* 2 x) (* 2 y))
;;           (+ (* 3 (expt x 2)) (* -6 x y) (* 3 (expt y 2)))
;;           (* (exp y) (exp x))))
   #+end_src

*** Exercise B.1: Chain Rule

    Let $F(x, y) = x^2y^3$, $G(x, y)=(F(x, y), y)$, and $H(x, y) = F(F(x, y),
    y)$, so that $H = F \circ G$.

    a. Compute $\partial_0 F(x, y)$ and $\partial_1 F(x, y)$.
    b. Compute $\partial_0 F(F(x, y), y)$ and $\partial_1 F(F(x, y), y)$.
    c. Compute $\partial_0 G(x, y)$ and $\partial_1 G(x, y)$.
    d. Compute $DF(a, b)$, $DG(3, 5)$ and $DH(3a^2, 5b^3)$.

*** Exercise B.2: Computing Derivatives

    We can represent functions of multiple arguments as procedures in several
    ways, depending upon how we wish to use them. The simplest idea is to
    identify the procedure arguments with the function's arguments.

    For example, we could write implementations of the functions that occur in
    exercise B.1 as follows:

    #+begin_src scheme
(define (f x y)
  (* (square x) (cube y)))

(define (g x y)
  (up (f x y) y))

(define (h x y)
  (f (f x y) y))
    #+end_src

    With this choice it is awkward to compose a function that takes multiple
    arguments, such as $f$, with a function that produces a tuple of those
    arguments, such as $g$. Alternatively, we can represent the function
    arguments as slots of a tuple data structure, and then composition with a
    function that produces such a data structure is easy. However, this choice
    requires the procedures to build and take apart structures.

    For example, we may define procedures that implement the functions above as
    follows:

    #+begin_src scheme
(define (f v)
  (let ((x (ref v 0))
        (y (ref v 1)))
    (* (square x) (cube y))))



(define (g v)
  (let ((x (ref v 0))
        (y (ref v 1)))
    (up (f v) y)))

(define h (compose f g))
    #+end_src

    Repeat exercise B.1 using the computer. Explore both implementations of
    multiple-argument functions.

* Footnotes

[fn:3] Partial derivative operators such as =(partial 2)= are operators, so
=(expt (partial 1) 2)= is a second partial derivative.

[fn:2] To emphasize the relationship of simple tuple structures to matrix
notation we often format =up= tuples as vertical arrangements of components and
=down= tuples as horizontal arrangements of components. However, we could just
as well have written this tuple as $\left[\left(\cos \theta, \sin \theta\right),
\left(−\sin \theta, \cos \theta\right)\right]$.

[fn:1] The procedure =print-expression= can be used in a program to print a
simplified version of an expression. The default printer in the user interface
incorporates the simplifier.
